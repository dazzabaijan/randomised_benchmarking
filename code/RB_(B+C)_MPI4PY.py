# -*- coding: utf-8 -*-
"""
Created on Sat Jul 20 16:11:04 2019

@author: dn16018

Randomised benchmarking non-Clifford gates for one qubit
"""
import numpy as np
import matplotlib.pyplot as plt
import time
import sys
from scipy.optimize import curve_fit
#
# Include mpi4py and get info
#
from mpi4py import MPI
comm = MPI.COMM_WORLD
numtasks = comm.Get_size()
taskid = comm.Get_rank()
MASTER = 0
TAG1 = 1
TAG2 = 2
TAG3 = 3
TAG4 = 4

init_state = np.array([[1, 0], [0, 0]], dtype=complex)

# Clifford group
II = np.eye(2, dtype=complex)
X = np.array([[0, 1], [1, 0]], dtype=complex)
Y = np.array([[0, -1j], [1j, 0]], dtype=complex)
Z = np.array([[1, 0], [0, -1]], dtype=complex)
PPP = (-II + 1j*X + 1j*Y + 1j*Z)/2
PPM = (-II + 1j*X + 1j*Y - 1j*Z)/2
PMM = (-II + 1j*X - 1j*Y - 1j*Z)/2
MMM = (-II - 1j*X - 1j*Y - 1j*Z)/2
MMP = (-II - 1j*X - 1j*Y + 1j*Z)/2
MPP = (-II - 1j*X + 1j*Y + 1j*Z)/2
PMP = (-II + 1j*X - 1j*Y + 1j*Z)/2
MPM = (-II - 1j*X + 1j*Y - 1j*Z)/2
cliffords = np.array([II, X, Y, Z, PPP, PPM, PMM, MMM, MMP, MPP, PMP, MPM])
paulis = np.array([II, X, Y, Z])
B = (1/np.sqrt(6-2*np.sqrt(3)))*np.array([[1-1j, np.sqrt(3)-1],
                                         [np.sqrt(3)-1, -1-1j]], dtype=complex)


def c_matrix(n):
    """
    C_n matrix used to generate the non-Clifford gate sets
    for 4*n
    C_n := [[exp(+i*2pi/n), 0],
            [0, exp(-i*2pi/n)]]
    Args:
        n (int): A number

    Returns:
        ndarray: A block matrix of C_n matrices.
    """

    exp = np.exp(1j*np.pi/n)
    exp_n = np.array([[exp, 0], [0, exp.conj()]], dtype=complex)
    c_matrix = np.array([exp_n**i for i in range(1, n, 1)], dtype=complex)
    return np.concatenate(([np.identity(2, dtype=complex)], c_matrix))


def non_clifford_group(n):
    """
    4*n Non-Clifford construction (2-designs)
    e.g. n = 3
    12-Cliffords := {II, X, Y, Z} x {II, D, D^2} where D = B*C_3*B^{dagger}

    for 4*n
    non-Cliffords := {B^{dagger} x {II, X, Y, Z} x B x {II, C_{2n},...,
                     C_{2n}^{n-1}}}
    Args:
        n (int): A number

    Returns:
        ndarray: A block matrix of 2-designs gate set.
    """

    conjugated_pauli = compute_channel_operation(np.array([II, X, Y, Z]),
                                                 B.conj().T,
                                                 B).reshape(4, 1, 2, 2)
    return (conjugated_pauli@c_matrix(n)).reshape(4*n, 2, 2)


def depolarizing_error(mean, std_dev, sample_size):
    """
    Depolarizing quantum error channel.
    D(rho) -> (1-p)*rho + (p/3)*(X*rho*X + Y*rho*Y + Z*rho*Z)

    Args:
        noise_mean (float): Mean of the Gaussian distribution
        std_dev (float): Standard deviation of the Gaussian distribution
        sample_size (int): Size of the random number generated.

    Returns:
        ndarray: A block matrix of depolarizing error matrices.
    """

    # Randomly drawing from a Gaussian distribution
    param = np.random.normal(mean, std_dev, (1, sample_size))

    # Redraw elements that are negative from the Gaussian distribution
    np.putmask(param, param < 0, np.random.normal(mean, std_dev))

    # Broadcast the drawn numbers to compute ndarrays of error matrices
    XYZ = ([np.sqrt(param/3)]*np.array([[X, Y, Z]]).T).T
    III = ([np.sqrt(1-param)]*np.array([[II]]).T).T
    return np.hstack((III, XYZ)).transpose(1, 0, 3, 2)


def frame_potential(designs, t):
    """
    Computes the frame potential for t-designs, defined as:
    frame_potential -> (1/K^t)*sum_{i=1, j=1}^n |Tr[U_{i}^{dagger}*U_{j}]|^{2t}

    Args:
        designs (2x2 matrices): A list of t-designs gate set
        t (int): A number

    Returns:
        number (float): The result of computing the frame potential.
    """

    # Computes hermitian tranpose of the t-designs
    designs_herm = designs.transpose(0, 2, 1).conj()

    # Computes the trace of sums of matrix multiplication
    traced_list = np.trace(designs_herm.reshape(len(designs), 1, 2, 2)@designs,
                           axis1=2, axis2=3)
    return np.sum(np.abs(traced_list)**(2*t))/((len(designs))**t)


def operator_groups(sample_size, n=None):
    """
    Generates the original Clifford gate set, or Clifford gate set by a basis
    change via matrix B or the non-Clifford gate sets generated by C_n matrix.

    Args:
        sample_size (int): Size of the ndarray/number of operations running in
                           parallel.
        n : n=None    -> Original Clifford gate set
            n="pauli" -> Just the Pauli gate set
            n=int     -> Non Clifford gate set
    Returns:
        ndarray: A block matrix of unitary error matrices.
    """

    if n is None:
        return cliffords[np.random.choice(cliffords.shape[0], sample_size)]
    if n is not None:
        if n is "pauli":
            return paulis[np.random.choice(paulis.shape[0], sample_size)]
        else:
            gate_set = non_clifford_group(n)
            return gate_set[np.random.choice(gate_set.shape[0], sample_size)]


def unitary_error(sd, sample_size):
    """
    Given 3 randomly Gaussian distributed parameters (a,b,c), the unitary noise
    is defined as:
    U(a,b,c) -> [[exp(-i(a+c)/2)*cos(b/2), exp(-i(a-c)/2)*sin(b/2)],
                 [-exp(i(a-c)/2)*sin(b/2), exp(+i(a+c)/2)*cos(b/2)]]
    Here an ndarray of parameters (a,b,c) is randomly generated from a Gaussian
    distribution, broadcasted to calculate the matrix elements and then
    reshaped to give an ndarray of unitary errors matrices for vectorization.

    Args:
        sd (float): Std. dev of the Gaussian distribution with mean = 0.
        sample_size (int): Size of the ndarray/number of operations running in
                           parallel.

    Returns:
        ndarray: A block matrix of unitary error matrices.
    """

    # Random sampling from Gaussian distribution
    params = np.random.normal(0, sd, (sample_size, 3))

    # Computes error matrix elements
    e_1 = np.exp(-1j*(params[:, 0]+params[:, 2])/2)*np.cos(params[:, 1]/2)
    e_2 = np.exp(-1j*(params[:, 0]-params[:, 2])/2)*np.sin(params[:, 1]/2)
    return np.array([[e_1, e_2], [-e_2.conj(), e_1.conj()]],
                    dtype=complex).transpose(2, 0, 1)


def compute_channel_operation(rho, gates):
    """
    Given a quantum state's density function rho, the effect of the
    channel on this state is:
    rho -> sum_{i=1}^n E_i * rho * E_i^dagger

    Args:
        rho (2x2 matrix): A density function array of shape (2,2)
        gates (list): List of quantum gates(matrices)

    Returns:
        matrix: The result of applying the list of quantum gates
    """

    return np.sum(gates@rho@gates.transpose(0, 1, 3, 2).conj(), axis=0)


def init_tensor(input_state, sample_size):
    """
    Given a quantum state(density operator), this function generates an amount
    of it according to "sample_size" into a block matrix/tensor/ndarray, for
    vectorization purposes.

    Args:
        input_state (2x2 matrix): A density function array of shape (2,2)
        sample_size (int): Number of matrices within the block matrix
    Returns:
        ndarray: An ndarray with dim (sample_size, 2, 2) with input_state as
                 entries.
    """

    return np.broadcast_to(input_state, (sample_size,)+input_state.shape)


def randomized_benchmarking(input_state, seq_length, sample_size,
                            noise_mean, noise_sd, noise2_sd, n=None):
    sequence = []

    # State preparation noise map
    prep_noise = depolarizing_error(noise_mean, noise_sd, sample_size)
    rho_tensor = init_tensor(input_state, sample_size)
    rho = compute_channel_operation(rho_tensor, prep_noise)

    for j in range(1, seq_length+1, 1):
        # Gate operation noise map
        depol_noise = depolarizing_error(noise_mean, noise_sd, sample_size)
        unit_noise = unitary_error(noise2_sd, sample_size)
        q_gates = operator_groups(sample_size, n)
        sequence.append(q_gates)

        i_ideal_operator = unit_noise@depol_noise@q_gates
        rho = compute_channel_operation(rho, i_ideal_operator)

    # Final CPTP map of random noises
    depol_noise = depolarizing_error(noise_mean, noise_sd, sample_size)
    unit_noise = unitary_error(noise2_sd, sample_size)

    # Computes the Hermitian of the inverse of the forward gates sequence
    inverse_gate = np.array(sequence[::-1])[0]

    # Computes multi dot products
    for el in np.array(sequence[::-1])[1:]:
        inverse_gate = inverse_gate@el

    # Final ideal&noisy density operator
    unitary_undo = inverse_gate.transpose(0, 2, 1).conj()
    f_ideal_operator = unit_noise@depol_noise@unitary_undo
    f_noisy_operator = compute_channel_operation(rho, f_ideal_operator)

    # Final measurement noise map
    spam_noise = depolarizing_error(noise_mean, noise_sd, sample_size)
    rho_tensor = init_tensor(input_state, sample_size)
    noisy_input_state = compute_channel_operation(rho_tensor, spam_noise)

    # Measure observables and compute average fidelity
    traced = np.trace(noisy_input_state@f_noisy_operator, axis1=1, axis2=2)
    avg_fidelity = np.average(traced)

    return np.real(avg_fidelity)


def exponential(s, a, b, c):
    """
    A scaled exponential function for curve fitting specifically for RB.
    y = a(2*b - 1)^s + c

    Args:
        s, a, b, c : array-like, dtype=float

    Returns:
         list: The result of passing the x-parameters through this function.

    """
    return a * (2 * b - 1)**s + c


def get_data(rho, seq_length, sample_size,
             noise_mean, noise_sd, noise2_sd, n=None):
    starttime = time.time()
    length = np.zeros(seq_length-2, dtype=np.float64)
    fidelity_s = np.zeros(seq_length-2, dtype=np.float64)
    if taskid==MASTER: # Only MASTER prints this
        print("[INFO] Input state\t\t: {}".format(str(rho)))
        print("[INFO] Sequence length\t\t: {}".format(seq_length))
        print("[INFO] Sequence samples\t\t: {}".format(sample_size))
        print("[INFO] Depolarizing noise mean\t: {}".format(noise_mean))
        print("[INFO] Depolarizing std. dev\t: {}".format(noise_sd))
        print("[INFO] Unitary noise std. dev\t: {}".format(noise2_sd))
        print("[INFO] n\t\t\t: {}\n".format(n))

#
# Compute start and end points, assuming n^2 sort of scaling
#
    istart = int(seq_length*np.sqrt(taskid/numtasks)) + 1
    iend = int(seq_length*np.sqrt((taskid+1)/numtasks)) + 1
    if istart==1: istart=2
    if iend>seq_length: iend=seq_length
    print("Rank: ",taskid," start: ",istart," end: ",iend)

    for s in range(istart, iend, 1):
        avg_fidelity = randomized_benchmarking(rho, s, sample_size, noise_mean,
                                               noise_sd, noise2_sd, n=None)
#        sys.stdout.write("\r" + "gate applied: " + str(s))
        length[s-2] = s
        fidelity_s[s-2] = avg_fidelity
    
    if taskid != MASTER: # Only Workers do this
        offset = istart-2
        chunksize = iend - istart
        comm.send(offset, dest=MASTER, tag=TAG1)
        comm.send(chunksize, dest=MASTER, tag=TAG2)
        comm.Send(length[offset:offset+chunksize], dest=MASTER, tag=TAG3)
        comm.Send(fidelity_s[offset:offset+chunksize], dest=MASTER, tag=TAG4)
        timeElapsed = time.time() - starttime
        print("Time elapsed for worker {}: {} seconds".format(taskid,timeElapsed))


    if taskid==MASTER: # Only Master node does this
        for source in range(1,numtasks):
            offset = comm.recv(source=source, tag=TAG1)
            chunksize = comm.recv(source=source, tag=TAG2)
            comm.Recv([length[offset:],chunksize,MPI.DOUBLE], source=source, tag=TAG3)
            comm.Recv([fidelity_s[offset:],chunksize,MPI.DOUBLE], source=source, tag=TAG4)
        timeElapsed = time.time() - starttime
        print("Time elapsed for Master: {} seconds".format(timeElapsed))

        np.savetxt('filename.txt', np.vstack((length, fidelity_s)).T,
                   delimiter=',\t ')
        plt.figure(figsize=(15, 7.5))
        popt, pcov = curve_fit(exponential, length, fidelity_s,
                               bounds=(0, [0.5, 1, 0.5]), method=None)
        t = np.linspace(1, seq_length-2, seq_length-2) 
        error = np.sqrt(np.diag(pcov))
        variance = np.average(np.abs(np.array(exponential(t, *popt)) -
                              np.array(fidelity_s)))
        params = tuple([item for sublist in zip(popt, error) for item in sublist])

        fit_label = 'fit: a=%.10f$\\pm$%.10f\n     ' + \
                    'b=%.10f$\\pm$%.10f \n     c=%.10f$\\pm$%.10f'
        plt.plot(length, exponential(t, *popt), 'r-', label=fit_label % params)
        plt.plot(length, fidelity_s, 'b-', label='data: $\\sigma^2$=%7.4f' %
                 (variance))
        ideal_fidelity = (0.5 + (1 - noise_mean)*(1 + np.exp(-0.5*noise2_sd**2) +
                          np.exp(-noise2_sd**2))*(np.exp(-0.5*noise2_sd**2)/6))
        print("\nIdeal average gate fidelity: ", ideal_fidelity)

        plt.title("1 Qubit Randomized Benchmarking", fontsize=20)
        plt.xlabel("Clifford length", fontsize=20)
        plt.ylabel("Fidelity", fontsize=20)
        plt.xlim(0, (seq_length-2))
        plt.ylim(0.5, 1)
        plt.legend(shadow=True, fontsize=20)

        plt.show()


starttime = time.time()
get_data(init_state, 302, 50, 0.01, 0.001, 0.1, n=None)
timeElapsed = time.time() - starttime
if taskid==0: print("Time elapsed: {} seconds".format(timeElapsed))
